{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a7f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU, Bidirectional, Embedding, Input, Concatenate, Dot, Activation,Attention\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceda45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24a6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Concatenate the training and testing data\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06094364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to the same length\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b989dd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert sequences to one-hot encoded vectors\n",
    "X_train = np.array([to_categorical(seq, num_classes=max_features) for seq in X_train])\n",
    "X_test = np.array([to_categorical(seq, num_classes=max_features) for seq in X_test])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa1932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8a0ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RNN\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(100, input_shape=(max_length, max_features)))\n",
    "model_rnn.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22664011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "500/500 [==============================] - 79s 153ms/step - loss: 0.6077 - accuracy: 0.6494 - val_loss: 0.4573 - val_accuracy: 0.7887\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 73s 146ms/step - loss: 0.4568 - accuracy: 0.7897 - val_loss: 0.4291 - val_accuracy: 0.8081\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 70s 140ms/step - loss: 0.4357 - accuracy: 0.8019 - val_loss: 0.4198 - val_accuracy: 0.8160\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 69s 138ms/step - loss: 0.4203 - accuracy: 0.8112 - val_loss: 0.4159 - val_accuracy: 0.8164\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 74s 148ms/step - loss: 0.4057 - accuracy: 0.8204 - val_loss: 0.4409 - val_accuracy: 0.8074\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 76s 152ms/step - loss: 0.4031 - accuracy: 0.8229 - val_loss: 0.4187 - val_accuracy: 0.8126\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.4021 - accuracy: 0.8237 - val_loss: 0.4152 - val_accuracy: 0.8139\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 76s 152ms/step - loss: 0.3974 - accuracy: 0.8279 - val_loss: 0.4246 - val_accuracy: 0.8116\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 75s 149ms/step - loss: 0.3941 - accuracy: 0.8286 - val_loss: 0.4386 - val_accuracy: 0.8099\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 74s 149ms/step - loss: 0.4008 - accuracy: 0.8246 - val_loss: 0.4260 - val_accuracy: 0.8156\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 75s 150ms/step - loss: 0.3944 - accuracy: 0.8272 - val_loss: 0.4190 - val_accuracy: 0.8141\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 67s 134ms/step - loss: 0.3751 - accuracy: 0.8405 - val_loss: 0.4159 - val_accuracy: 0.8190\n",
      "Epoch 13/50\n",
      "104/500 [=====>........................] - ETA: 25s - loss: 0.3726 - accuracy: 0.8434"
     ]
    }
   ],
   "source": [
    "model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_rnn.fit(X_train, y_train, batch_size=64, epochs=50, validation_data=(X_val, y_val))\n",
    "scores_rnn = model_rnn.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Simple RN N Test Accuracy: %.2f%%\" % (scores_rnn[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6c5ff7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 21ms/step\n",
      "Confusion Matrix:\n",
      "[[4091  947]\n",
      " [1094 3868]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Evaluate the model on the test set\n",
    "y_pred_prob = model_rnn.predict(X_test)\n",
    "y_pred = np.round(y_pred_prob).flatten()\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "384521f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(100, input_shape=(max_length, max_features)))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "049a40a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 111s 219ms/step - loss: 0.4566 - accuracy: 0.7821 - val_loss: 0.3799 - val_accuracy: 0.8279\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 121s 241ms/step - loss: 0.3705 - accuracy: 0.8361 - val_loss: 0.3846 - val_accuracy: 0.8265\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 123s 246ms/step - loss: 0.3465 - accuracy: 0.8464 - val_loss: 0.4127 - val_accuracy: 0.8227\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 118s 235ms/step - loss: 0.3350 - accuracy: 0.8537 - val_loss: 0.3799 - val_accuracy: 0.8279\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 125s 249ms/step - loss: 0.3164 - accuracy: 0.8625 - val_loss: 0.3873 - val_accuracy: 0.8325\n",
      "LSTM Test Accuracy: 83.35%\n"
     ]
    }
   ],
   "source": [
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_val, y_val))\n",
    "scores_lstm = model_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"LSTM Test Accuracy: %.2f%%\" % (scores_lstm[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a704ba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 15s 45ms/step\n",
      "Confusion Matrix:\n",
      "[[4324  714]\n",
      " [ 951 4011]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred_prob = model_lstm.predict(X_test)\n",
    "y_pred = np.round(y_pred_prob).flatten()\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c03818f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(100, input_shape=(max_length, max_features)))\n",
    "model_gru.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ab2c456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 113s 222ms/step - loss: 0.4670 - accuracy: 0.7666 - val_loss: 0.3852 - val_accuracy: 0.8278\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 113s 226ms/step - loss: 0.3622 - accuracy: 0.8382 - val_loss: 0.3681 - val_accuracy: 0.8334\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 115s 229ms/step - loss: 0.3342 - accuracy: 0.8546 - val_loss: 0.3708 - val_accuracy: 0.8342\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 114s 228ms/step - loss: 0.3094 - accuracy: 0.8653 - val_loss: 0.3904 - val_accuracy: 0.8257\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 112s 223ms/step - loss: 0.2928 - accuracy: 0.8739 - val_loss: 0.3798 - val_accuracy: 0.8379\n",
      "GRU Test Accuracy: 84.14%\n"
     ]
    }
   ],
   "source": [
    "model_gru.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_gru.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_val, y_val))\n",
    "scores_gru = model_gru.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"GRU Test Accuracy: %.2f%%\" % (scores_gru[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "444107e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 32ms/step\n",
      "Confusion Matrix:\n",
      "[[4296  742]\n",
      " [ 844 4118]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred_prob = model_gru.predict(X_test)\n",
    "y_pred = np.round(y_pred_prob).flatten()\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b6de2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional LSTM\n",
    "model_bilstm = Sequential()\n",
    "model_bilstm.add(Bidirectional(LSTM(100), input_shape=(max_length, max_features)))\n",
    "model_bilstm.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5525a5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 201s 395ms/step - loss: 0.4952 - accuracy: 0.7581 - val_loss: 0.4218 - val_accuracy: 0.8066\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 191s 382ms/step - loss: 0.3726 - accuracy: 0.8351 - val_loss: 0.4061 - val_accuracy: 0.8240\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 192s 384ms/step - loss: 0.3488 - accuracy: 0.8471 - val_loss: 0.3724 - val_accuracy: 0.8317\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 191s 382ms/step - loss: 0.3297 - accuracy: 0.8562 - val_loss: 0.3762 - val_accuracy: 0.8284\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 187s 374ms/step - loss: 0.3037 - accuracy: 0.8689 - val_loss: 0.3783 - val_accuracy: 0.8375\n",
      "Bidirectional LSTM Test Accuracy: 82.86%\n"
     ]
    }
   ],
   "source": [
    "model_bilstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_bilstm.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_val, y_val))\n",
    "scores_bilstm = model_bilstm.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Bidirectional LSTM Test Accuracy: %.2f%%\" % (scores_bilstm[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4227505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 30s 89ms/step\n",
      "Confusion Matrix:\n",
      "[[4060  978]\n",
      " [ 736 4226]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred_prob = model_bilstm.predict(X_test)\n",
    "y_pred = np.round(y_pred_prob).flatten()\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9bc015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "500/500 [==============================] - 319s 633ms/step - loss: 0.4532 - accuracy: 0.7845 - val_loss: 0.3803 - val_accuracy: 0.8286\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 313s 626ms/step - loss: 0.3666 - accuracy: 0.8384 - val_loss: 0.4014 - val_accuracy: 0.8158\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 317s 633ms/step - loss: 0.3565 - accuracy: 0.8441 - val_loss: 0.3707 - val_accuracy: 0.8327\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 319s 638ms/step - loss: 0.3393 - accuracy: 0.8521 - val_loss: 0.3732 - val_accuracy: 0.8332\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 321s 642ms/step - loss: 0.3257 - accuracy: 0.8577 - val_loss: 0.3657 - val_accuracy: 0.8365\n",
      "Bidirectional LSTM with Attention Test Accuracy: 83.56%\n"
     ]
    }
   ],
   "source": [
    "#Bi-LSTM with Attention\n",
    "\n",
    "# Reshape the labels to match the shape of the logits\n",
    "y_train = np.reshape(y_train, (-1, 1))\n",
    "y_test = np.reshape(y_test, (-1,  1))\n",
    "y_val = np.reshape(y_val, (-1,  1))\n",
    "# Define the input layer\n",
    "input_seq = Input(shape=(max_length, max_features))\n",
    "\n",
    "# Bidirectional LSTM layer\n",
    "lstm_units = 100\n",
    "lstm_layer = Bidirectional(LSTM(lstm_units, return_sequences=True))(input_seq)\n",
    "\n",
    "# Attention mechanism\n",
    "attention = Attention()([lstm_layer, lstm_layer])\n",
    "\n",
    "# Concatenate the LSTM output and attention weights\n",
    "concatenated = Concatenate(axis=-1)([lstm_layer, attention])\n",
    "# Dense layer for classification\n",
    "output = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_seq, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Bidirectional LSTM with Attention Test Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3553828f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100, 1000)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "y_test = np.reshape(y_test, (-1,))\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7695b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 55s 175ms/step\n",
      "Confusion Matrix:\n",
      "[[2983 2055]\n",
      " [2857 2105]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int).flatten()\n",
    "# Reshape y_pred to match the shape of y_test\n",
    "y_pred_reshaped = y_pred[:y_test..\n",
    "                         shape[0]]\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_reshaped)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "978582ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8f67d719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your review: this movie is too overated.\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Predicted sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# Obtain user input for the review\n",
    "user_review = input(\"Enter your review: \")\n",
    "\n",
    "# Preprocess the user input\n",
    "user_input = tokenizer.texts_to_sequences([user_review])\n",
    "user_input = pad_sequences(user_input, maxlen=max_length)\n",
    "\n",
    "# Convert user input to one-hot encoded vectors\n",
    "user_input = np.array([to_categorical(seq, num_classes=max_features) for seq in user_input])\n",
    "\n",
    "# Reshape the user input to match the input shape of the model\n",
    "user_input = np.reshape(user_input, (1, max_length, max_features))\n",
    "\n",
    "# Make predictions using the trained model\n",
    "prediction = model.predict(user_input)\n",
    "\n",
    "# Interpret the prediction\n",
    "sentiment = \"\"\n",
    "if prediction[0][0] < 0.5:\n",
    "    sentiment = \"Negative\"\n",
    "elif prediction[0][0] > 0.5:\n",
    "    sentiment = \"Positive\"\n",
    "else:\n",
    "    sentiment = \"Neutral\"\n",
    "\n",
    "# Print the predicted sentiment\n",
    "print(\"Predicted sentiment: \" + sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511af041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
